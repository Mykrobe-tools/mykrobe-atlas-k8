---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {BITNAMI}-{KAFKA}-scripts
  namespace: {NAMESPACE}
  labels:
    app.kubernetes.io/name: {KAFKA}
    app.kubernetes.io/instance: {BITNAMI}
data:
  setup.sh: |-
    #!/bin/bash

    ID="${MY_POD_NAME#"{BITNAMI}-{KAFKA}-"}"
    if [[ -f "/bitnami/kafka/data/meta.properties" ]]; then
        export KAFKA_CFG_BROKER_ID="$(grep "broker.id" /bitnami/kafka/data/meta.properties | awk -F '=' '{print $2}')"
    else
        export KAFKA_CFG_BROKER_ID="$((ID + 0))"
    fi

    exec /entrypoint.sh /run.sh
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {BITNAMI}-{ZOOKEEPER}
  namespace: {NAMESPACE}
  labels:
    app.kubernetes.io/name: {ZOOKEEPER}
    app.kubernetes.io/instance: {BITNAMI}
    app.kubernetes.io/component: {ZOOKEEPER}
    role: {ZOOKEEPER}
spec:
  serviceName: {BITNAMI}-{ZOOKEEPER}-headless
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: {ZOOKEEPER}
      app.kubernetes.io/instance: {BITNAMI}
      app.kubernetes.io/component: {ZOOKEEPER}
  template:
    metadata:
      name: {BITNAMI}-{ZOOKEEPER}
      labels:
        app.kubernetes.io/name: {ZOOKEEPER}
        app.kubernetes.io/instance: {BITNAMI}
        app.kubernetes.io/component: {ZOOKEEPER}
    spec:
      
      serviceAccountName: {PREFIX}-insight
      securityContext:
        fsGroup: 1001
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: {ZOOKEEPER}
                    app.kubernetes.io/instance: {BITNAMI}
                    app.kubernetes.io/component: {ZOOKEEPER}
                namespaces:
                  - "insight"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      containers:
        - name: {ZOOKEEPER}
          image: {ZOOKEEPER_IMAGE}
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          command:
            - bash
            - -ec
            - |
                # Execute entrypoint as usual after obtaining ZOO_SERVER_ID
                # check ZOO_SERVER_ID in persistent volume via myid
                # if not present, set based on POD hostname
                if [[ -f "/bitnami/zookeeper/data/myid" ]]; then
                  export ZOO_SERVER_ID="$(cat /bitnami/zookeeper/data/myid)"
                else
                  HOSTNAME=`hostname -s`
                  if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
                    ORD=${BASH_REMATCH[2]}
                    export ZOO_SERVER_ID=$((ORD + 1 ))
                  else
                    echo "Failed to get index from hostname $HOST"
                    exit 1
                  fi
                fi
                exec /entrypoint.sh /run.sh
          resources: 
            requests:
              memory: "{REQUEST_ZOOKEEPER_MEMORY}"
              cpu: "{REQUEST_ZOOKEEPER_CPU}"
              ephemeral-storage: "{ZOOKEEPER_EPHERMERAL_STORAGE}"        
            limits:
              memory: "{LIMIT_ZOOKEEPER_MEMORY}"
              cpu: "{LIMIT_ZOOKEEPER_CPU}"
              ephemeral-storage: "{ZOOKEEPER_EPHERMERAL_STORAGE}"
          env:
            - name: ZOO_DATA_LOG_DIR
              value: ""
            - name: ZOO_PORT_NUMBER
              value: "2181"
            - name: ZOO_TICK_TIME
              value: "2000"
            - name: ZOO_INIT_LIMIT
              value: "10"
            - name: ZOO_SYNC_LIMIT
              value: "5"
            - name: ZOO_MAX_CLIENT_CNXNS
              value: "60"
            - name: ZOO_4LW_COMMANDS_WHITELIST
              value: "srvr, mntr, ruok"
            - name: ZOO_LISTEN_ALLIPS_ENABLED
              value: "no"
            - name: ZOO_AUTOPURGE_INTERVAL
              value: "0"
            - name: ZOO_AUTOPURGE_RETAIN_COUNT
              value: "3"
            - name: ZOO_MAX_SESSION_TIMEOUT
              value: "40000"
            - name: ZOO_SERVERS
              value: {BITNAMI}-{ZOOKEEPER}-0.{BITNAMI}-{ZOOKEEPER}-headless.{NAMESPACE}.svc.cluster.local:2888:3888::1 
            - name: ZOO_ENABLE_AUTH
              value: "no"
            - name: ZOO_HEAP_SIZE
              value: "1024"
            - name: ZOO_LOG_LEVEL
              value: "ERROR"
            - name: ALLOW_ANONYMOUS_LOGIN
              value: "yes"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
          ports:
            
            - name: client
              containerPort: 2181
            
            
            - name: follower
              containerPort: 2888
            - name: election
              containerPort: 3888
          livenessProbe:
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: data
              mountPath: /bitnami/zookeeper
      volumes:
  volumeClaimTemplates:
    - metadata:
        name: data
        annotations:
      spec:
        storageClassName: "{STORAGE_CLASS}"
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "{REQUEST_ZOOKEEPER_STORAGE}"
          limits:
            storage: "{LIMIT_ZOOKEEPER_STORAGE}"
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {BITNAMI}-{KAFKA}
  namespace: {NAMESPACE}
  labels:
    app.kubernetes.io/name: {KAFKA}
    app.kubernetes.io/instance: {BITNAMI}
    app.kubernetes.io/component: {KAFKA}
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: {KAFKA}
      app.kubernetes.io/instance: {BITNAMI}
      app.kubernetes.io/component: {KAFKA}
  serviceName: {BITNAMI}-{KAFKA}-headless
  updateStrategy:
    type: "RollingUpdate"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {KAFKA}
        app.kubernetes.io/instance: {BITNAMI}
        app.kubernetes.io/component: {KAFKA}
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: {KAFKA}
                    app.kubernetes.io/instance: {BITNAMI}
                namespaces:
                  - "insight"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      serviceAccountName: {PREFIX}-insight
      containers:
        - name: {KAFKA}
          image: {KAFKA_BROKER_IMAGE}
          imagePullPolicy: "IfNotPresent"
          command:
            - /scripts/setup.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KAFKA_CFG_ZOOKEEPER_CONNECT
              value: "{BITNAMI}-{ZOOKEEPER}"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "INTERNAL"
            - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
              value: "INTERNAL:PLAINTEXT,CLIENT:PLAINTEXT"
            - name: KAFKA_CFG_LISTENERS
              value: "INTERNAL://:9093,CLIENT://:9092"
            - name: KAFKA_CFG_ADVERTISED_LISTENERS
              value: "INTERNAL://$(MY_POD_NAME).{BITNAMI}-{KAFKA}-headless.insight.svc.cluster.local:9093,CLIENT://$(MY_POD_NAME).{BITNAMI}-{KAFKA}-headless.insight.svc.cluster.local:9092"
            - name: ALLOW_PLAINTEXT_LISTENER
              value: "yes"
            - name: KAFKA_VOLUME_DIR
              value: "/bitnami/kafka"
            - name: KAFKA_LOG_DIR
              value: "/opt/bitnami/kafka/logs"
            - name: KAFKA_CFG_DELETE_TOPIC_ENABLE
              value: "false"
            - name: KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE
              value: "true"
            - name: KAFKA_HEAP_OPTS
              value: "-Xmx1024m -Xms1024m"
            - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MESSAGES
              value: "10000"
            - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MS
              value: "1000"
            - name: KAFKA_CFG_LOG_RETENTION_BYTES
              value: "1073741824"
            - name: KAFKA_CFG_LOG_RETENTION_CHECK_INTERVALS_MS
              value: "300000"
            - name: KAFKA_CFG_LOG_RETENTION_HOURS
              value: "168"
            - name: KAFKA_CFG_MESSAGE_MAX_BYTES
              value: "1000012"
            - name: KAFKA_CFG_LOG_SEGMENT_BYTES
              value: "1073741824"
            - name: KAFKA_CFG_LOG_DIRS
              value: "/bitnami/kafka/data"
            - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_CFG_NUM_IO_THREADS
              value: "8"
            - name: KAFKA_CFG_NUM_NETWORK_THREADS
              value: "3"
            - name: KAFKA_CFG_NUM_PARTITIONS
              value: "1"
            - name: KAFKA_CFG_NUM_RECOVERY_THREADS_PER_DATA_DIR
              value: "1"
            - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES
              value: "102400"
            - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES
              value: "104857600"
            - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES
              value: "102400"
            - name: KAFKA_CFG_ZOOKEEPER_CONNECTION_TIMEOUT_MS
              value: "6000"
          ports:
            - name: kafka-client
              containerPort: 9092
            - name: kafka-internal
              containerPort: 9093
          livenessProbe:
            tcpSocket:
              port: kafka-client
            initialDelaySeconds: 10
            timeoutSeconds: 5
            failureThreshold: 
            periodSeconds: 
            successThreshold: 
          readinessProbe:
            tcpSocket:
              port: kafka-client
            initialDelaySeconds: 5
            timeoutSeconds: 5
            failureThreshold: 6
            periodSeconds: 
            successThreshold: 
          volumeMounts:
            - name: data
              mountPath: /bitnami/kafka
            - name: logs
              mountPath: /opt/bitnami/kafka/logs
            - name: scripts
              mountPath: /scripts/setup.sh
              subPath: setup.sh
          resources: 
            requests:
              memory: "{REQUEST_KAFKA_MEMORY}"
              cpu: "{REQUEST_KAFKA_CPU}"    
              ephemeral-storage: "{KAFKA_EPHERMERAL_STORAGE}"   
            limits:
              memory: "{LIMIT_KAFKA_MEMORY}"
              cpu: "{LIMIT_KAFKA_CPU}"
              ephemeral-storage: "{KAFKA_EPHERMERAL_STORAGE}"
      volumes:
        - name: scripts
          configMap:
            name: {BITNAMI}-{KAFKA}-scripts
            defaultMode: 0755
        - name: logs
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        storageClassName: "{STORAGE_CLASS}"
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "{REQUEST_KAFKA_STORAGE}"
          limits:
            storage: "{LIMIT_KAFKA_STORAGE}"
